{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import pandas as pd\n",
    "import os\n",
    "from typing import List\n",
    "from enum import Enum\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.output_parsers.enum import EnumOutputParser\n",
    "\n",
    "\n",
    "with open('config/config.txt') as f:\n",
    "    for line in f:\n",
    "        env_data = line.split(',')\n",
    "        os.environ[env_data[0]] = env_data[1]\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo',temperature=0.7)\n",
    "\n",
    "reviews = pd.read_csv('data/review_sample.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_significant_ideas(text):\n",
    "    # Define the prompt to instruct the model to extract significant ideas\n",
    "    prompt = f\"Please summarize the following text by extracting the significant ideas as short sentences. SEPARATE EACH SENTENCE WITH COMMAS ONLY:\\n\\n{text}\"\n",
    "    \n",
    "    # Use LangChain's llm to call the OpenAI API\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    return response\n",
    "\n",
    "ideas = {}\n",
    "\n",
    "# Extract significant ideas\n",
    "for i in range(5):\n",
    "    significant_ideas = extract_significant_ideas(reviews.text[i])\n",
    "    ideas[reviews.review_id[i]] = significant_ideas.content.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QEkyAdsrVo7tEsANDN7O9g': ['Missed Marvin',\n",
       "  ' enjoyed chocolate shake',\n",
       "  ' went later in the day',\n",
       "  ' best time to go is when they open',\n",
       "  ' Marvin is entertaining.'],\n",
       " 'kIViMGM4JTHHozAE1r9boA': ['Best breakfast in a long time',\n",
       "  ' disappointed with breakfast before',\n",
       "  ' Cammellias was amazing',\n",
       "  ' had the omelet at the bottom of the menu',\n",
       "  ' so good! Brother had the Mexican',\n",
       "  ' very tasty',\n",
       "  ' pecan omelet is to die for',\n",
       "  ' thinner than most',\n",
       "  ' order ASAP',\n",
       "  ' busy',\n",
       "  ' service is personable and awesome.'],\n",
       " 'LpHt30LaQHAtBs-j_EYUUw': ['Recently visited new French Quarter location',\n",
       "  ' enjoyed as much as Carrollton location',\n",
       "  ' Get Manhattan Omelette',\n",
       "  ' To die for.'],\n",
       " 'WqCjrz_fV-n6y_nDxme2lA': ['One of my favorite places',\n",
       "  ' Marvin is high energy and fun',\n",
       "  ' awesome service',\n",
       "  ' food is amazing',\n",
       "  ' best breakfast place',\n",
       "  ' New Orleans landmark',\n",
       "  ' well worth the wait',\n",
       "  ' huge smiley face.'],\n",
       " 'J8kc5pwyAtpl1Wm91RopYQ': ['Total disappointment',\n",
       "  ' filthy',\n",
       "  ' rundown',\n",
       "  ' stained napkins',\n",
       "  ' rusted equipment',\n",
       "  ' staff outfits dirty',\n",
       "  ' staff clowned around',\n",
       "  ' obnoxious noises',\n",
       "  ' greasy food',\n",
       "  ' fake butter',\n",
       "  ' imitation cheese',\n",
       "  ' surly person at register',\n",
       "  ' terrible meal',\n",
       "  ' needs renovation',\n",
       "  ' newly trained staff.']}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Boolean(Enum):\n",
    "    TRUE = \"TRUE\"\n",
    "    FALSE = \"FALSE\"\n",
    "\n",
    "def merge_related_ideas(idea_0, idea_1):\n",
    "    parser = EnumOutputParser(enum=Boolean)\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Please look at the following two ideas and decide whether they express the same or a very similar thing: \n",
    "        \n",
    "        Idea 1: {idea_0}\n",
    "        \n",
    "        Idea 2: {idea_1}\n",
    "\n",
    "        Instructions: {instructions}\n",
    "        \"\"\"\n",
    "    ).partial(instructions=parser.get_format_instructions())\n",
    "    chain = prompt | llm | parser\n",
    "    response = chain.invoke({\"idea_0\": idea_0, \"idea_1\": idea_1})\n",
    "    return response.value == 'TRUE'\n",
    "\n",
    "a = ideas['LpHt30LaQHAtBs-j_EYUUw'][-1]\n",
    "b = ideas['kIViMGM4JTHHozAE1r9boA'][4]\n",
    "\n",
    "r = merge_related_ideas(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' To die for.', ' so good! Brother had the Mexican')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
